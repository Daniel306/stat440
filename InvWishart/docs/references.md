
[WP:Invertible Matrix](https://en.wikipedia.org/wiki/Invertible_matrix#Blockwise_inversion) has a surprising amount of insight.

[Tim Davis](http://www.cise.ufl.edu/research/sparse/), whose sparse matrix solvers underly everything that's fast in numerical computation: matlab, scipy, CUDA, and R.

Dahtah on [Why an inverse-Wishart prior may not be such a good idea](http://dahtah.wordpress.com/2012/03/07/why-an-inverse-wishart-prior-may-not-be-such-a-good-idea/).
Datah's [follow up](https://dahtah.wordpress.com/2012/08/22/priors-of-convenience/).

http://stackoverflow.com/questions/18349053/fastest-way-for-multiplying-a-matrix-to-a-vector:

* mmult (??)
* sweep (??)
* %*%
* t(t(mat)*v))
