
Validation testing
 - Moments 
   - derive (in math and latex) the expected moments, check if we get them o
     (moments are handy because they are all expectations, which can be tested--by the law of large numbers--with taking sample means)
 - Marginals
   - k-s test?
 - 


tips: R doesn't have pointers (everything is by-value), so passing matrices
 from function to function literally does memcpys.
 So writing in C will speed things up simply by avoiding the copies.

maybeidea: Bartlett's Method gives us dists of the entries of the square root of a Wishart matrix.
   What if we work out the dist of the inverse of that (which we call Gamma in the notes). (tip from prof: it "should" be a matrix where each entry is a sum of normals which is a normal)

Performance testing
 - cases: algorithm X impl
   
   impl: (
   python
   cython
   scipy with explicitly marking matrices as upper/lower triangular (see: ...)
   scipy with vectorized ops (eg. can we vectorize adding mu to all samples or is that no better than a for loop?)
   scipy with for loops
   R
   R with explicitly marking matrices as upper/lower triangular (the functions 'backsolve' and 'forwardsolve' do this)
   R with vectorized ops
   R with for loops
   Rcpp
   )

   algorithm: (
   naive
   snappysample
   factoredsnappysample (in which we only compute chol(Psi) once)
   )
   
   for each case, do a parameter sweep on:
   ( d, df, n )
   and measure
   ( runtime )

Stability Testing
 - at what point do the algorithms get numerically unstable?
